#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π Telegram-–±–æ—Ç –Ω–∞ –±–∞–∑–µ YandexGPT –∏ DeepSeek.
–û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
"""

import os
import time
from typing import Dict, List
from dataclasses import dataclass
from dotenv import load_dotenv
from openai import OpenAI
from yandex_cloud_ml_sdk import YCloudML
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

YANDEX_FOLDER_ID = os.getenv("YANDEX_FOLDER_ID")
YANDEX_AUTH = os.getenv("YANDEX_AUTH")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
HF_TOKEN = os.getenv("HF_TOKEN")

if not YANDEX_FOLDER_ID or not YANDEX_AUTH or not TELEGRAM_BOT_TOKEN:
    raise ValueError("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ YANDEX_FOLDER_ID, YANDEX_AUTH –∏ TELEGRAM_BOT_TOKEN –≤ .env —Ñ–∞–π–ª–µ!")

# === 1. –°–û–ó–î–ê–ù–ò–ï SDK –ö–õ–ò–ï–ù–¢–û–í ===
# YandexGPT
yandex_sdk = YCloudML(folder_id=YANDEX_FOLDER_ID, auth=YANDEX_AUTH)

# HuggingFace (DeepSeek)
hf_client = OpenAI(
    base_url="https://router.huggingface.co/v1",
    api_key=HF_TOKEN or ""
)

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
MODELS = {
    "yandex": "YandexGPT",
    "deepseek": "DeepSeek-V3"
}

# === 2. –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢ ===
SYSTEM_PROMPT = """
–æ—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ—á–µ–Ω—å –ø–æ–¥—Ä–æ–±–Ω–æ
–ò–°–ü–û–õ–¨–ó–£–ô –í–°–ï –î–û–°–¢–£–ü–ù–´–ï –¢–û–ö–ï–ù–´ –î–õ–Ø –û–¢–í–ï–¢–ê
"""

# === 3. –ò–°–¢–û–†–ò–Ø –°–û–û–ë–©–ï–ù–ò–ô –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===
# –ö–ª—é—á - ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Telegram, –∑–Ω–∞—á–µ–Ω–∏–µ - —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
user_histories: Dict[int, List[dict]] = {}

# === 4. –¢–ï–ú–ü–ï–†–ê–¢–£–†–ê –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===
# 0 = —Å—Ç—Ä–æ–≥–∏–µ –æ—Ç–≤–µ—Ç—ã, 1 = –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
user_temperatures: Dict[int, float] = {}

# === 5. –í–´–ë–†–ê–ù–ù–ê–Ø –ú–û–î–ï–õ–¨ –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===
user_models: Dict[int, str] = {}  # "yandex" –∏–ª–∏ "deepseek"

# === 6. –õ–ò–ú–ò–¢ –¢–û–ö–ï–ù–û–í –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===
user_max_tokens: Dict[int, int] = {}  # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ (0 = –±–µ–∑ –ª–∏–º–∏—Ç–∞)

# === 7. –ü–†–ï–î–´–î–£–©–ï–ï –ó–ù–ê–ß–ï–ù–ò–ï INPUT TOKENS (–¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞) ===
user_prev_input_tokens: Dict[int, int] = {}

def get_history(user_id: int) -> List[dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—É—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç."""
    if user_id not in user_histories:
        user_histories[user_id] = [{"role": "system", "text": SYSTEM_PROMPT}]
    return user_histories[user_id]


def clear_history(user_id: int):
    """–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_histories[user_id] = [{"role": "system", "text": SYSTEM_PROMPT}]
    user_prev_input_tokens[user_id] = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ —Ç–æ–∫–µ–Ω–æ–≤

def change_system_prompt(user_id: int, prompt: str):
    """–ò–∑–º–µ–Ω—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_histories[user_id].append({"role": "system", "text": prompt})


def get_temperature(user_id: int) -> float:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.5."""
    return user_temperatures.get(user_id, 0.5)


def set_temperature(user_id: int, temp: float):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_temperatures[user_id] = temp


def get_model(user_id: int) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é yandex."""
    return user_models.get(user_id, "yandex")


def set_model(user_id: int, model: str):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_models[user_id] = model


def get_max_tokens(user_id: int) -> int:
    """–ü–æ–ª—É—á–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 0 = –±–µ–∑ –ª–∏–º–∏—Ç–∞."""
    return user_max_tokens.get(user_id, 0)


def set_max_tokens(user_id: int, max_tokens: int):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_max_tokens[user_id] = max_tokens


@dataclass
class AgentResponse:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏."""
    text: str
    input_tokens: int      # –¢–æ–∫–µ–Ω—ã –≤—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏ (context)
    output_tokens: int     # –¢–æ–∫–µ–Ω—ã –æ—Ç–≤–µ—Ç–∞
    total_tokens: int      # –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —ç—Ç–æ–º –∑–∞–ø—Ä–æ—Å–µ
    message_tokens: int    # –¢–æ–∫–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    time_seconds: float
    cost_rub: float  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ —Ä—É–±–ª—è—Ö
    model: str = ""  # –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏


# –¶–µ–Ω—ã YandexGPT (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ, —Ä—É–± –∑–∞ 1000 —Ç–æ–∫–µ–Ω–æ–≤)
PRICE_INPUT_PER_1K = 0.12   # –≤—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
PRICE_OUTPUT_PER_1K = 0.24  # –≤—ã—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã


def ask_yandex(history: List[dict], temperature: float, max_tokens: int = 0) -> tuple:
    """–ó–∞–ø—Ä–æ—Å –∫ YandexGPT. max_tokens –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç (completion), –Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç."""
    model = yandex_sdk.models.completions("yandexgpt")
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    if max_tokens > 0:
        result = model.configure(temperature=temperature, max_tokens=max_tokens).run(history)
    else:
        result = model.configure(temperature=temperature).run(history)
    
    response_text = ""
    input_tokens = 0
    output_tokens = 0
    
    for alt in result:
        if hasattr(alt, 'text'):
            response_text = alt.text
    
    if hasattr(result, 'usage'):
        usage = result.usage
        input_tokens = getattr(usage, 'input_text_tokens', 0)
        output_tokens = getattr(usage, 'completion_tokens', 0)
    
    return response_text, input_tokens, output_tokens


def ask_deepseek(history: List[dict], temperature: float, max_tokens: int = 0) -> tuple:
    """–ó–∞–ø—Ä–æ—Å –∫ DeepSeek —á–µ—Ä–µ–∑ HuggingFace."""
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞—Ç –∏—Å—Ç–æ—Ä–∏–∏ (text -> content)
    messages = []
    for msg in history:
        messages.append({
            "role": msg["role"],
            "content": msg.get("text", msg.get("content", ""))
        })
    
    kwargs = {
        "model": "deepseek-ai/DeepSeek-V3",
        "messages": messages,
        "temperature": temperature
    }
    if max_tokens > 0:
        kwargs["max_tokens"] = max_tokens
    
    completion = hf_client.chat.completions.create(**kwargs)
    
    response_text = completion.choices[0].message.content or ""
    input_tokens = completion.usage.prompt_tokens if completion.usage else 0
    output_tokens = completion.usage.completion_tokens if completion.usage else 0
    
    return response_text, input_tokens, output_tokens


def ask_agent(user_id: int, question: str) -> AgentResponse:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤–æ–ø—Ä–æ—Å –∞–≥–µ–Ω—Ç—É –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏."""
    history = get_history(user_id)
    model = get_model(user_id)
    temperature = get_temperature(user_id)
    max_tokens = get_max_tokens(user_id)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ input_tokens –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏—è
    prev_input_tokens = user_prev_input_tokens.get(user_id, 0)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é
    history.append({"role": "user", "text": question})
    
    # –ó–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
    start_time = time.time()
    
    # –ó–∞–ø—Ä–æ—Å –∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    if model == "deepseek":
        response_text, input_tokens, output_tokens = ask_deepseek(history, temperature, max_tokens)
    else:
        response_text, input_tokens, output_tokens = ask_yandex(history, temperature, max_tokens)
    
    elapsed_time = time.time() - start_time
    total_tokens = input_tokens + output_tokens
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    # (—Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ç–µ–∫—É—â–∏–º context –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–º context + –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç)
    message_tokens = input_tokens - prev_input_tokens
    if message_tokens < 0:
        message_tokens = input_tokens  # –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è –±—ã–ª–∞ –æ—á–∏—â–µ–Ω–∞
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    # (input_tokens + output_tokens = —Å–ª–µ–¥—É—é—â–∏–π prev_input_tokens)
    user_prev_input_tokens[user_id] = input_tokens + output_tokens
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å (–ø—Ä–∏–º–µ—Ä–Ω–æ)
    cost = (input_tokens / 1000 * PRICE_INPUT_PER_1K) + (output_tokens / 1000 * PRICE_OUTPUT_PER_1K)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
    history.append({"role": "assistant", "text": response_text})
    
    return AgentResponse(
        text=response_text,
        input_tokens=input_tokens,
        output_tokens=output_tokens,
        total_tokens=total_tokens,
        message_tokens=message_tokens,
        time_seconds=elapsed_time,
        cost_rub=cost,
        model=MODELS[model]
    )


# === –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ===

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user_id = update.effective_user.id
    clear_history(user_id)
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –ø—Ä–æ—Å—Ç–æ–π –±–æ—Ç-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –æ—Ç–≤–µ—á—É.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/model - –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å (YandexGPT / DeepSeek)\n"
        "/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞\n"
        "/set_system_prompt <—Ç–µ–∫—Å—Ç> - –∏–∑–º–µ–Ω–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç\n"
        "/temperature - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É\n"
        "/set_temperature <0-1> - –∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É\n"
        "/max_tokens - –ø–æ–∫–∞–∑–∞—Ç—å –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤\n"
        "/set_max_tokens <—á–∏—Å–ª–æ> - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤"
    )


async def cmd_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /clear"""
    user_id = update.effective_user.id
    clear_history(user_id)
    await update.message.reply_text("üóë –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞!")


async def cmd_set_system_prompt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /set_system_prompt <–Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç>"""
    user_id = update.effective_user.id
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã
    # context.args —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã
    if not context.args:
        await update.message.reply_text(
            "‚ö†Ô∏è –£–∫–∞–∂–∏ –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã.\n\n"
        )
        return
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
    new_prompt = " ".join(context.args)
    
    # –ú–µ–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç
    change_system_prompt(user_id, new_prompt)
    
    await update.message.reply_text(
        f"‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑–º–µ–Ω—ë–Ω!\n\n"
        f"–ù–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç:\n{new_prompt}"
    )


async def cmd_temperature(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /temperature - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É"""
    user_id = update.effective_user.id
    current_temp = get_temperature(user_id)
    await update.message.reply_text(f"üå° –¢–µ–∫—É—â–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {current_temp}")


async def cmd_set_temperature(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /set_temperature <—á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1>"""
    user_id = update.effective_user.id
    
    if not context.args:
        await update.message.reply_text(
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /set_temperature <—á–∏—Å–ª–æ>\n"
            "‚Ä¢ 0 - —Å—Ç—Ä–æ–≥–∏–µ, —Ç–æ—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã\n"
            "‚Ä¢ 1 - –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ, —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã\n\n"
            "–ü—Ä–∏–º–µ—Ä: /set_temperature 0.7"
        )
        return
    
    try:
        new_temp = float(context.args[0])
        if not 0 <= new_temp <= 1:
            raise ValueError("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç 0 –¥–æ 1")
        
        set_temperature(user_id, new_temp)
        await update.message.reply_text(f"üå° –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {new_temp}")
    except ValueError as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}\n–£–∫–∞–∂–∏ —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1")


async def cmd_max_tokens(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /max_tokens - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤"""
    user_id = update.effective_user.id
    current_limit = get_max_tokens(user_id)
    if current_limit == 0:
        await update.message.reply_text("üìè –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤: –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π")
    else:
        await update.message.reply_text(f"üìè –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤: {current_limit}")


async def cmd_set_max_tokens(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /set_max_tokens <—á–∏—Å–ª–æ>"""
    user_id = update.effective_user.id
    
    if not context.args:
        current_limit = get_max_tokens(user_id)
        await update.message.reply_text(
            f"üìè –¢–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç: {current_limit if current_limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /set_max_tokens <—á–∏—Å–ª–æ>\n"
            "‚Ä¢ 0 - –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π\n"
            "‚Ä¢ 100-8000 - –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ\n\n"
            "–ü—Ä–∏–º–µ—Ä: /set_max_tokens 500"
        )
        return
    
    try:
        new_limit = int(context.args[0])
        if new_limit < 0:
            raise ValueError("–õ–∏–º–∏—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º")
        
        set_max_tokens(user_id, new_limit)
        if new_limit == 0:
            await update.message.reply_text("üìè –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ —Å–Ω—è—Ç (–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        else:
            await update.message.reply_text(f"üìè –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {new_limit}")
    except ValueError as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}\n–£–∫–∞–∂–∏ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ >= 0")


async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /model - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–Ω–æ–ø–∫–∏ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏"""
    user_id = update.effective_user.id
    current_model = get_model(user_id)
    
    # –°–æ–∑–¥–∞—ë–º –∫–Ω–æ–ø–∫–∏
    keyboard = [
        [
            InlineKeyboardButton(
                f"{'‚úÖ ' if current_model == 'yandex' else ''}YandexGPT",
                callback_data="model_yandex"
            ),
            InlineKeyboardButton(
                f"{'‚úÖ ' if current_model == 'deepseek' else ''}DeepSeek-V3",
                callback_data="model_deepseek"
            ),
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        f"ü§ñ –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {MODELS[current_model]}\n\n–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:",
        reply_markup=reply_markup
    )


async def handle_model_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏"""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    
    if query.data == "model_yandex":
        set_model(user_id, "yandex")
        selected = "YandexGPT"
    elif query.data == "model_deepseek":
        set_model(user_id, "deepseek")
        selected = "DeepSeek-V3"
    else:
        return
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ —Å –Ω–æ–≤–æ–π –≥–∞–ª–æ—á–∫–æ–π
    current_model = get_model(user_id)
    keyboard = [
        [
            InlineKeyboardButton(
                f"{'‚úÖ ' if current_model == 'yandex' else ''}YandexGPT",
                callback_data="model_yandex"
            ),
            InlineKeyboardButton(
                f"{'‚úÖ ' if current_model == 'deepseek' else ''}DeepSeek-V3",
                callback_data="model_deepseek"
            ),
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.edit_message_text(
        f"ü§ñ –ú–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞: {selected}\n\n–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:",
        reply_markup=reply_markup
    )


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = update.effective_user.id
    user_message = update.message.text
    
    if not user_message:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –±–æ—Ç "–ø–µ—á–∞—Ç–∞–µ—Ç"
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –∞–≥–µ–Ω—Ç–∞
        response = ask_agent(user_id, user_message)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        stats = (
            f"\n\n---\n"
            f"ü§ñ {response.model} | ‚è± {response.time_seconds:.2f}s | üí∞ {response.cost_rub:.4f}‚ÇΩ\n"
            f"üí¨ Your message: {response.message_tokens} tokens\n"
            f"üì• Context (history): {response.input_tokens} tokens\n"
            f"üì§ Response: {response.output_tokens} tokens\n"
            f"üìä This request total: {response.total_tokens} tokens"
        )
        
        await update.message.reply_text(response.text + stats)
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    # –°–æ–∑–¥–∞—ë–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("clear", cmd_clear))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("set_system_prompt", cmd_set_system_prompt))
    app.add_handler(CommandHandler("temperature", cmd_temperature))
    app.add_handler(CommandHandler("set_temperature", cmd_set_temperature))
    app.add_handler(CommandHandler("max_tokens", cmd_max_tokens))
    app.add_handler(CommandHandler("set_max_tokens", cmd_set_max_tokens))
    app.add_handler(CallbackQueryHandler(handle_model_callback, pattern="^model_"))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()

